2023-04-19 21:40:48,105 - Service.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping https://www.op.gg/. . .
2023-04-19 21:40:49,660 - Service.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-19 21:40:58,408 - Service.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping https://www.aasdsdop.gg/. . .
2023-04-19 21:40:58,543 - Service.LoggerContext.__get_raw_html_from_link() on line 32 - WARNING - Failed with: HTTPSConnectionPool(host='www.aasdsdop.gg', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000261624AF860>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
2023-04-19 21:40:58,543 - Service.LoggerContext.__get_raw_html_from_link() on line 38 - INFO - Will try again with non-secure connection ...
2023-04-19 21:40:58,544 - Service.LoggerContext.scrape_link() on line 21 - ERROR - Scraping Failed . . .
2023-04-19 21:41:51,629 - Service.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping https://www.aasdsdop.gg/. . .
2023-04-19 21:41:51,780 - Service.LoggerContext.__get_raw_html_from_link() on line 32 - WARNING - Failed with: HTTPSConnectionPool(host='www.aasdsdop.gg', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002195B8DFF98>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
2023-04-19 21:41:51,782 - Service.LoggerContext.__get_raw_html_from_link() on line 38 - INFO - Will try again with non-secure connection ...
2023-04-19 21:41:51,782 - Service.LoggerContext.scrape_link() on line 21 - CRITICAL - Scraping Failed . . .
2023-04-19 21:41:51,782 - Service.LoggerContext.main() on line 15 - ERROR - HTTPSConnectionPool(host='www.aasdsdop.gg', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002195B8DFF98>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
2023-04-19 21:42:43,979 - Service.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping https://www.aasdsdop.gg/. . .
2023-04-19 21:42:44,118 - Service.LoggerContext.__get_raw_html_from_link() on line 32 - WARNING - Failed with: HTTPSConnectionPool(host='www.aasdsdop.gg', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001FB64460F28>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
2023-04-19 21:42:44,118 - Service.LoggerContext.__get_raw_html_from_link() on line 33 - WARNING - Will try again with non-secure connection ...
2023-04-19 21:42:44,119 - Service.LoggerContext.scrape_link() on line 21 - CRITICAL - Scraping Failed . . .
2023-04-19 21:42:44,119 - Service.LoggerContext.main() on line 15 - ERROR - HTTPSConnectionPool(host='www.aasdsdop.gg', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001FB62874B00>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
2023-04-19 21:47:04,131 - Service.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping https://www.aasdsdop.gg/. . .
2023-04-19 21:47:04,184 - Service.LoggerContext.__get_raw_html_from_link() on line 32 - WARNING - Failed with: HTTPSConnectionPool(host='www.aasdsdop.gg', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002548F8D3A20>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
2023-04-19 21:47:04,184 - Service.LoggerContext.__get_raw_html_from_link() on line 33 - WARNING - Will try again with non-secure connection ...
2023-04-19 21:47:04,185 - Service.LoggerContext.scrape_link() on line 21 - CRITICAL - Scraping Failed . . .
2023-04-19 21:47:04,185 - Service.LoggerContext.main() on line 15 - ERROR - HTTPSConnectionPool(host='www.aasdsdop.gg', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002548DF846D8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
2023-04-19 23:58:26,779 - Service.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping https://www.aasdsdop.gg/. . .
2023-04-19 23:58:26,817 - Service.LoggerContext.__get_raw_html_from_link() on line 32 - WARNING - Failed with: HTTPSConnectionPool(host='www.aasdsdop.gg', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001A32980E0F0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
2023-04-19 23:58:26,817 - Service.LoggerContext.__get_raw_html_from_link() on line 33 - WARNING - Will try again with non-secure connection ...
2023-04-19 23:58:26,817 - Service.LoggerContext.scrape_link() on line 21 - CRITICAL - Scraping Failed . . .
2023-04-19 23:58:26,818 - Service.LoggerContext.main() on line 15 - ERROR - HTTPSConnectionPool(host='www.aasdsdop.gg', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001A3296CF8D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))
2023-04-19 23:59:44,328 - Service.LoggerContext.test() on line 11 - INFO - got profile id: 1
2023-04-20 00:03:01,060 - Service.LoggerContext.test() on line 16 - INFO - got profile id: 1
2023-04-20 00:11:24,888 - Service.LoggerContext.get_jobs_from_profile_id() on line 27 - ERROR - The current Flask app is not registered with this 'SQLAlchemy' instance. Did you forget to call 'init_app', or did you create multiple 'SQLAlchemy' instances?
2023-04-20 00:26:19,586 - Service.LoggerContext.get_jobs_from_profile_id() on line 26 - ERROR - The current Flask app is not registered with this 'SQLAlchemy' instance. Did you forget to call 'init_app', or did you create multiple 'SQLAlchemy' instances?
2023-04-20 00:26:51,030 - Service.LoggerContext.get_jobs_from_profile_id() on line 26 - ERROR - The current Flask app is not registered with this 'SQLAlchemy' instance. Did you forget to call 'init_app', or did you create multiple 'SQLAlchemy' instances?
2023-04-20 00:27:31,900 - Service.LoggerContext.get_jobs_from_profile_id() on line 26 - ERROR - The current Flask app is not registered with this 'SQLAlchemy' instance. Did you forget to call 'init_app', or did you create multiple 'SQLAlchemy' instances?
2023-04-20 00:29:30,417 - Service.LoggerContext.get_jobs_from_profile_id() on line 26 - ERROR - The current Flask app is not registered with this 'SQLAlchemy' instance. Did you forget to call 'init_app', or did you create multiple 'SQLAlchemy' instances?
2023-04-20 00:41:44,533 - Service.LoggerContext.get_jobs_from_profile_id() on line 26 - ERROR - Object of type Job is not JSON serializable
2023-04-20 00:42:00,460 - Service.LoggerContext.get_jobs_from_profile_id() on line 26 - ERROR - Object of type Job is not JSON serializable
2023-04-20 00:42:05,006 - Service.LoggerContext.get_jobs_from_profile_id() on line 26 - ERROR - Object of type Job is not JSON serializable
2023-04-20 00:50:57,139 - Service.LoggerContext.get_jobs_from_profile_id() on line 26 - ERROR - Object of type Job is not JSON serializable
2023-04-20 00:51:10,032 - Service.LoggerContext.get_jobs_from_profile_id() on line 26 - ERROR - Object of type Job is not JSON serializable
2023-04-20 00:55:01,806 - Service.LoggerContext.get_jobs_from_profile_id() on line 27 - ERROR - Object of type Job is not JSON serializable
2023-04-20 00:55:36,632 - Service.LoggerContext.get_jobs_from_profile_id() on line 27 - ERROR - Object of type Job is not JSON serializable
2023-04-20 00:57:30,968 - Service.LoggerContext.get_jobs_from_profile_id() on line 27 - ERROR - Object of type method is not JSON serializable
2023-04-20 04:56:18,385 - Services.LoggerContext.get_all_profiles() on line 69 - ERROR - Could not determine join condition between parent/child tables on relationship Job.diffs - there are no foreign keys linking these tables.  Ensure that referencing columns are associated with a ForeignKey or ForeignKeyConstraint, or specify a 'primaryjoin' expression.
2023-04-20 04:59:46,013 - Services.LoggerContext.get_all_profiles() on line 69 - ERROR - When initializing mapper Mapper[Job(JobsTable)], expression 'scrapeddata' failed to locate a name ("name 'scrapeddata' is not defined"). If this is a class name, consider adding this relationship() to the <class 'Models.DBGateway.Job'> class after both dependent classes have been defined.
2023-04-20 05:01:11,459 - Services.LoggerContext.get_all_profiles() on line 69 - ERROR - When initializing mapper Mapper[Job(JobsTable)], expression 'scraped_data' failed to locate a name ("name 'scraped_data' is not defined"). If this is a class name, consider adding this relationship() to the <class 'Models.DBGateway.Job'> class after both dependent classes have been defined.
2023-04-20 05:02:13,185 - Services.LoggerContext.get_all_profiles() on line 69 - ERROR - When initializing mapper Mapper[Job(JobsTable)], expression 'scraped_data' failed to locate a name ("name 'scraped_data' is not defined"). If this is a class name, consider adding this relationship() to the <class 'Models.DBGateway.Job'> class after both dependent classes have been defined.
2023-04-20 05:17:02,221 - Services.LoggerContext.get_jobs_from_profile_id() on line 29 - ERROR - 404 Not Found: The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.
2023-04-20 05:20:35,119 - Services.LoggerContext.get_jobs_from_profile_id() on line 28 - ERROR - No profile found for 5
2023-04-20 05:20:56,495 - Services.LoggerContext.get_jobs_from_profile_id() on line 28 - ERROR - No profile found with profile id 5
2023-04-20 05:35:00,285 - Services.LoggerContext.get_diffs_from_job_id() on line 42 - ERROR - Mapper 'Mapper[ScrapedData(ScrapedDataTable)]' has no property 'job'.  If this property was indicated from other mappers or configure events, ensure registry.configure() has been called.
2023-04-20 05:40:00,981 - Services.LoggerContext.get_diffs_from_job_id() on line 42 - ERROR - Mapper 'Mapper[ScrapedData(ScrapedDataTable)]' has no property 'job'.  If this property was indicated from other mappers or configure events, ensure registry.configure() has been called.
2023-04-20 05:41:03,171 - Services.LoggerContext.get_diffs_from_job_id() on line 42 - ERROR - Mapper 'Mapper[ScrapedData(ScrapedDataTable)]' has no property 'job'.  If this property was indicated from other mappers or configure events, ensure registry.configure() has been called.
2023-04-20 05:41:05,462 - Services.LoggerContext.get_diffs_from_job_id() on line 42 - ERROR - One or more mappers failed to initialize - can't proceed with initialization of other mappers. Triggering mapper: 'Mapper[Job(JobsTable)]'. Original exception was: Mapper 'Mapper[ScrapedData(ScrapedDataTable)]' has no property 'job'.  If this property was indicated from other mappers or configure events, ensure registry.configure() has been called.
2023-04-20 05:41:54,611 - Services.LoggerContext.get_diffs_from_job_id() on line 42 - ERROR - Mapper 'Mapper[ScrapedData(ScrapedDataTable)]' has no property 'job'.  If this property was indicated from other mappers or configure events, ensure registry.configure() has been called.
2023-04-20 05:46:13,814 - Services.LoggerContext.get_diffs_from_job_id() on line 42 - ERROR - [Errno 22] Invalid argument
2023-04-20 05:46:18,888 - Services.LoggerContext.get_diffs_from_job_id() on line 42 - ERROR - [Errno 22] Invalid argument
2023-04-20 05:46:30,334 - Services.LoggerContext.get_diffs_from_job_id() on line 42 - ERROR - [Errno 22] Invalid argument
2023-04-20 05:51:32,288 - Services.LoggerContext.get_diffs_from_job_id() on line 42 - ERROR - 'datetime.datetime' object has no attribute 'isofortmat'
2023-04-20 05:51:36,365 - Services.LoggerContext.get_diffs_from_job_id() on line 42 - ERROR - 'datetime.datetime' object has no attribute 'isofortmat'
2023-04-20 05:55:47,083 - Services.LoggerContext.get_checks_from_job_id() on line 60 - ERROR - 'datetime.datetime' object has no attribute 'isofortmat'
2023-04-20 05:56:41,630 - Services.LoggerContext.get_checks_from_job_id() on line 60 - ERROR - No job found with job id 4
2023-04-20 11:19:42,199 - Services.LoggerContext.get_checks_from_job_id() on line 60 - ERROR - (psycopg2.OperationalError) server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

[SQL: SELECT "JobsTable".j_id AS "JobsTable_j_id", "JobsTable".job_name AS "JobsTable_job_name", "JobsTable".link AS "JobsTable_link", "JobsTable".frequency AS "JobsTable_frequency", "JobsTable".last_updated AS "JobsTable_last_updated", "JobsTable".next_update AS "JobsTable_next_update", "JobsTable".p_id AS "JobsTable_p_id", "JobsTable".s_id AS "JobsTable_s_id" 
FROM "JobsTable" 
WHERE "JobsTable".j_id = %(pk_1)s]
[parameters: {'pk_1': '4'}]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
2023-04-20 11:20:31,269 - Services.LoggerContext.get_checks_from_job_id() on line 60 - ERROR - Job ID 4 does not exist
2023-04-20 11:23:20,598 - Services.LoggerContext.get_checks_from_job_id() on line 60 - ERROR - Job ID None does not exist
2023-04-20 11:44:20,173 - Services.LoggerContext.create_job() on line 109 - ERROR - Profile ID 5 does not exist
2023-04-20 12:31:12,784 - Services.LoggerContext.create_job() on line 109 - ERROR - Error creating backref 'scraped_data' on relationship 'Job.link': property of that name exists on mapper 'Mapper[ScrapedData(ScrapedDataTable)]'
2023-04-20 12:31:49,259 - Services.LoggerContext.create_job() on line 109 - ERROR - No module named 'WebsiteScraper'
2023-04-20 12:32:08,876 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-20 12:32:09,062 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-20 12:37:55,362 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-20 12:37:55,564 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-20 12:37:57,856 - Services.LoggerContext.create_job() on line 109 - ERROR - Job with link http://example.com/link3 already exists
2023-04-20 12:38:45,272 - Services.LoggerContext.create_job() on line 109 - ERROR - Job with link http://example.com/link3 already exists
2023-04-20 12:38:49,556 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-20 12:38:49,660 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-20 12:38:58,738 - Services.LoggerContext.create_job() on line 109 - ERROR - Job with job name job1 already exists
2023-04-20 12:39:03,053 - Services.LoggerContext.create_job() on line 109 - ERROR - Job with job name job1 already exists
2023-04-20 13:09:45,786 - Services.LoggerContext.create_job() on line 109 - ERROR - Job with job name job1 already exists
2023-04-20 13:37:43,359 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-20 13:37:43,473 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-20 13:37:43,874 - Services.LoggerContext.create_job() on line 109 - ERROR - (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "DiffsTable_pkey"
DETAIL:  Key (d_id)=(1) already exists.

[SQL: INSERT INTO "DiffsTable" (scraped_diff, updated_on, s_id) VALUES (%(scraped_diff)s, %(updated_on)s, %(s_id)s) RETURNING "DiffsTable".d_id]
[parameters: {'scraped_diff': '- E\n+ Example Domain\nExample Domain\nT\n- ample Domai\n+ is domain is for use in illustrative examples in documents. You may use t\n- Exa\n+ is\n domain in literature without prior coordination or asking for permission.\nMore information...', 'updated_on': datetime.datetime(2023, 4, 20, 13, 37, 43, 752579), 's_id': 2}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2023-04-20 15:32:28,978 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-20 15:32:29,090 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-20 15:32:29,439 - Services.LoggerContext.create_job() on line 109 - ERROR - (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "ChecksTable_pkey"
DETAIL:  Key (c_id)=(1) already exists.

[SQL: INSERT INTO "ChecksTable" (status, checked_on, s_id) VALUES (%(status)s, %(checked_on)s, %(s_id)s) RETURNING "ChecksTable".c_id]
[parameters: {'status': 'First Check', 'checked_on': datetime.datetime(2023, 4, 20, 15, 32, 29, 333574), 's_id': 2}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2023-04-20 15:32:58,900 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-20 15:32:59,006 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-20 15:32:59,348 - Services.LoggerContext.create_job() on line 109 - ERROR - (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "ChecksTable_pkey"
DETAIL:  Key (c_id)=(2) already exists.

[SQL: INSERT INTO "ChecksTable" (status, checked_on, s_id) VALUES (%(status)s, %(checked_on)s, %(s_id)s) RETURNING "ChecksTable".c_id]
[parameters: {'status': 'First Check', 'checked_on': datetime.datetime(2023, 4, 20, 15, 32, 59, 226647), 's_id': 2}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2023-04-20 15:33:25,378 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-20 15:33:25,481 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-20 15:33:25,817 - Services.LoggerContext.create_job() on line 109 - ERROR - (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "ChecksTable_pkey"
DETAIL:  Key (c_id)=(3) already exists.

[SQL: INSERT INTO "ChecksTable" (status, checked_on, s_id) VALUES (%(status)s, %(checked_on)s, %(s_id)s) RETURNING "ChecksTable".c_id]
[parameters: {'status': 'First Check', 'checked_on': datetime.datetime(2023, 4, 20, 15, 33, 25, 721373), 's_id': 2}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2023-04-20 15:39:38,900 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-20 15:39:39,012 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-20 15:39:39,382 - Services.LoggerContext.create_job() on line 109 - ERROR - (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "DiffsTable_pkey"
DETAIL:  Key (d_id)=(1) already exists.

[SQL: INSERT INTO "DiffsTable" (scraped_diff, updated_on, s_id) VALUES (%(scraped_diff)s, %(updated_on)s, %(s_id)s) RETURNING "DiffsTable".d_id]
[parameters: {'scraped_diff': '- E\n+ Example Domain\nExample Domain\nT\n- ample Domai\n+ is domain is for use in illustrative examples in documents. You may use t\n- Exa\n+ is\n domain in literature without prior coordination or asking for permission.\nMore information...', 'updated_on': datetime.datetime(2023, 4, 20, 15, 39, 39, 281599), 's_id': 2}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2023-04-20 15:42:29,960 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-20 15:42:30,063 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-20 15:42:30,781 - Services.LoggerContext.test_send_email_success() on line 41 - INFO - Successfully sent email
2023-04-20 15:42:30,998 - Services.LoggerContext.create_job() on line 109 - ERROR - unsupported type for timedelta minutes component: str
2023-04-20 15:46:20,678 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-20 15:46:20,784 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-20 15:46:21,243 - Services.LoggerContext.create_job() on line 109 - ERROR - unsupported type for timedelta minutes component: str
2023-04-20 15:47:38,002 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-20 15:47:38,108 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-20 15:49:09,917 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-20 15:49:10,024 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-21 12:56:26,085 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-21 12:56:26,281 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-21 12:57:07,789 - Services.LoggerContext.create_job() on line 109 - ERROR - Job with job name job4 already exists
2023-04-21 13:09:16,045 - Services.LoggerContext.refresh_jobs() on line 122 - ERROR - 'method' object is not iterable
2023-04-21 13:09:32,794 - Services.LoggerContext.refresh_jobs() on line 122 - ERROR - 'method' object is not iterable
2023-04-21 14:31:00,665 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-21 14:31:00,846 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-21 14:31:02,716 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-21 14:31:02,834 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-21 14:31:04,139 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link3. . .
2023-04-21 14:31:04,261 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-21 14:39:56,977 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping https://www.sacanime.com/vendors-and-artists/artist-alley/artist-alley-registration/. . .
2023-04-21 14:39:57,318 - Services.LoggerContext.__get_raw_html_from_link() on line 32 - WARNING - Failed with: HTTPSConnectionPool(host='www.sacanime.com', port=443): Max retries exceeded with url: /vendors-and-artists/artist-alley/artist-alley-registration/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1045)')))
2023-04-21 14:39:57,318 - Services.LoggerContext.__get_raw_html_from_link() on line 33 - WARNING - Will try again with non-secure connection ...
2023-04-21 14:39:57,646 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-21 14:42:37,516 - Services.LoggerContext.refresh_stale_jobs() on line 95 - CRITICAL - Failed to send email Error:
2023-04-21 14:47:29,671 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-21 14:47:29,852 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-21 14:47:30,254 - Services.LoggerContext.__refresh_diffs_and_send_email__() on line 116 - CRITICAL - before func
2023-04-21 14:47:30,558 - Services.LoggerContext.__refresh_diffs_and_send_email__() on line 129 - CRITICAL - ayy lmao
2023-04-21 14:48:52,520 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link3. . .
2023-04-21 14:48:52,963 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-21 14:48:53,660 - Services.LoggerContext.__refresh_diffs_and_send_email__() on line 128 - CRITICAL - Failed to send email Error: No module named 'sib_api_v3_sdk'
2023-04-21 14:48:54,728 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-21 14:48:54,846 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-21 15:32:43,560 - Services.LoggerContext.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-21 15:32:43,856 - Services.LoggerContext.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-21 15:32:44,908 - Services.LoggerContext.create_job() on line 109 - ERROR - (psycopg2.errors.DatatypeMismatch) column "date_created" is of type timestamp with time zone but expression is of type text[]
LINE 1: ...mestamp, '2023-04-22T15:32:43.857082'::timestamp, ARRAY['dat...
                                                             ^
HINT:  You will need to rewrite or cast the expression.

[SQL: INSERT INTO "JobsTable" (job_name, frequency, last_updated, next_update, date_created, p_id, s_id) VALUES (%(job_name)s, %(frequency)s, %(last_updated)s, %(next_update)s, %(date_created)s, %(p_id)s, %(s_id)s) RETURNING "JobsTable".j_id]
[parameters: {'job_name': 'job4', 'frequency': '1440', 'last_updated': datetime.datetime(2023, 4, 21, 15, 32, 43, 857082), 'next_update': datetime.datetime(2023, 4, 22, 15, 32, 43, 857082), 'date_created': ['date_created'], 'p_id': '1', 's_id': 4}]
(Background on this error at: https://sqlalche.me/e/20/f405)
2023-04-21 15:35:55,146 - werkzeug._log() on line 224 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2023-04-21 15:35:55,146 - werkzeug._log() on line 224 - INFO - [33mPress CTRL+C to quit[0m
2023-04-21 15:35:55,147 - werkzeug._log() on line 224 - INFO -  * Restarting with stat
2023-04-21 15:35:58,030 - werkzeug._log() on line 224 - WARNING -  * Debugger is active!
2023-04-21 15:35:58,037 - werkzeug._log() on line 224 - INFO -  * Debugger PIN: 504-761-569
2023-04-21 15:36:11,206 - root.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-21 15:36:11,206 - urllib3.util.retry.from_int() on line 351 - DEBUG - Converted retries value: 0 -> Retry(total=0, connect=None, read=None, redirect=0, status=None)
2023-04-21 15:36:11,206 - urllib3.connectionpool._new_conn() on line 228 - DEBUG - Starting new HTTP connection (1): example.com:80
2023-04-21 15:36:11,409 - urllib3.connectionpool._make_request() on line 456 - DEBUG - http://example.com:80 "GET /link2 HTTP/1.1" 404 1256
2023-04-21 15:36:11,411 - root.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-21 15:36:12,450 - root.create_job() on line 109 - ERROR - (psycopg2.errors.DatatypeMismatch) column "date_created" is of type timestamp with time zone but expression is of type text[]
LINE 1: ...mestamp, '2023-04-22T15:36:11.411922'::timestamp, ARRAY['dat...
                                                             ^
HINT:  You will need to rewrite or cast the expression.

[SQL: INSERT INTO "JobsTable" (job_name, frequency, last_updated, next_update, date_created, p_id, s_id) VALUES (%(job_name)s, %(frequency)s, %(last_updated)s, %(next_update)s, %(date_created)s, %(p_id)s, %(s_id)s) RETURNING "JobsTable".j_id]
[parameters: {'job_name': 'job4', 'frequency': '1440', 'last_updated': datetime.datetime(2023, 4, 21, 15, 36, 11, 411922), 'next_update': datetime.datetime(2023, 4, 22, 15, 36, 11, 411922), 'date_created': ['date_created'], 'p_id': '1', 's_id': 5}]
(Background on this error at: https://sqlalche.me/e/20/f405)
2023-04-21 15:36:12,451 - werkzeug._log() on line 224 - INFO - 127.0.0.1 - - [21/Apr/2023 15:36:12] "[31m[1mPOST /api/jobs/create?job_name=job4&frequency=1440&profile_id=1&link=http://example.com/link2 HTTP/1.1[0m" 400 -
2023-04-21 15:38:00,380 - werkzeug._log() on line 224 - INFO -  * Detected change in '/Users/tobychow/Documents/GitHub/Website-Diff-Bot/Services/LoggerContext.py', reloading
2023-04-21 15:38:00,456 - werkzeug._log() on line 224 - INFO -  * Restarting with stat
2023-04-21 15:38:05,766 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/werkzeug/_internal.py._log() on line 224 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2023-04-21 15:38:05,767 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/werkzeug/_internal.py._log() on line 224 - INFO - [33mPress CTRL+C to quit[0m
2023-04-21 15:38:05,768 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/werkzeug/_internal.py._log() on line 224 - INFO -  * Restarting with stat
2023-04-21 15:38:08,692 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/werkzeug/_internal.py._log() on line 224 - WARNING -  * Debugger is active!
2023-04-21 15:38:08,699 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/werkzeug/_internal.py._log() on line 224 - INFO -  * Debugger PIN: 504-761-569
2023-04-21 15:38:09,409 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/Services/WebsiteScraper.py.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-21 15:38:09,410 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/urllib3/util/retry.py.from_int() on line 351 - DEBUG - Converted retries value: 0 -> Retry(total=0, connect=None, read=None, redirect=0, status=None)
2023-04-21 15:38:09,410 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/urllib3/connectionpool.py._new_conn() on line 228 - DEBUG - Starting new HTTP connection (1): example.com:80
2023-04-21 15:38:09,581 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/urllib3/connectionpool.py._make_request() on line 456 - DEBUG - http://example.com:80 "GET /link2 HTTP/1.1" 404 1256
2023-04-21 15:38:09,583 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/Services/WebsiteScraper.py.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-21 15:38:10,577 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/API/APIRouting.py.create_job() on line 109 - ERROR - (psycopg2.errors.DatatypeMismatch) column "date_created" is of type timestamp with time zone but expression is of type text[]
LINE 1: ...mestamp, '2023-04-22T15:38:09.583420'::timestamp, ARRAY['dat...
                                                             ^
HINT:  You will need to rewrite or cast the expression.

[SQL: INSERT INTO "JobsTable" (job_name, frequency, last_updated, next_update, date_created, p_id, s_id) VALUES (%(job_name)s, %(frequency)s, %(last_updated)s, %(next_update)s, %(date_created)s, %(p_id)s, %(s_id)s) RETURNING "JobsTable".j_id]
[parameters: {'job_name': 'job4', 'frequency': '1440', 'last_updated': datetime.datetime(2023, 4, 21, 15, 38, 9, 583420), 'next_update': datetime.datetime(2023, 4, 22, 15, 38, 9, 583420), 'date_created': ['date_created'], 'p_id': '1', 's_id': 6}]
(Background on this error at: https://sqlalche.me/e/20/f405)
2023-04-21 15:38:10,579 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/werkzeug/_internal.py._log() on line 224 - INFO - 127.0.0.1 - - [21/Apr/2023 15:38:10] "[31m[1mPOST /api/jobs/create?job_name=job4&frequency=1440&profile_id=1&link=http://example.com/link2 HTTP/1.1[0m" 400 -
2023-04-21 15:38:52,512 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/werkzeug/_internal.py._log() on line 224 - INFO -  * Detected change in '/Users/tobychow/Documents/GitHub/Website-Diff-Bot/Services/LoggerContext.py', reloading
2023-04-21 15:38:52,615 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/werkzeug/_internal.py._log() on line 224 - INFO -  * Restarting with stat
2023-04-21 15:38:55,887 - _internal.py._log() on line 224 - WARNING -  * Debugger is active!
2023-04-21 15:38:55,895 - _internal.py._log() on line 224 - INFO -  * Debugger PIN: 504-761-569
2023-04-21 15:38:56,597 - WebsiteScraper.py.scrape_link() on line 14 - INFO - Starting Scraping http://example.com/link2. . .
2023-04-21 15:38:56,597 - retry.py.from_int() on line 351 - DEBUG - Converted retries value: 0 -> Retry(total=0, connect=None, read=None, redirect=0, status=None)
2023-04-21 15:38:56,598 - connectionpool.py._new_conn() on line 228 - DEBUG - Starting new HTTP connection (1): example.com:80
2023-04-21 15:38:56,816 - connectionpool.py._make_request() on line 456 - DEBUG - http://example.com:80 "GET /link2 HTTP/1.1" 404 1256
2023-04-21 15:38:56,818 - WebsiteScraper.py.scrape_link() on line 18 - INFO - Scraping Success!
2023-04-21 15:38:57,903 - APIRouting.py.create_job() on line 109 - ERROR - (psycopg2.errors.DatatypeMismatch) column "date_created" is of type timestamp with time zone but expression is of type text[]
LINE 1: ...mestamp, '2023-04-22T15:38:56.818693'::timestamp, ARRAY['dat...
                                                             ^
HINT:  You will need to rewrite or cast the expression.

[SQL: INSERT INTO "JobsTable" (job_name, frequency, last_updated, next_update, date_created, p_id, s_id) VALUES (%(job_name)s, %(frequency)s, %(last_updated)s, %(next_update)s, %(date_created)s, %(p_id)s, %(s_id)s) RETURNING "JobsTable".j_id]
[parameters: {'job_name': 'job4', 'frequency': '1440', 'last_updated': datetime.datetime(2023, 4, 21, 15, 38, 56, 818693), 'next_update': datetime.datetime(2023, 4, 22, 15, 38, 56, 818693), 'date_created': ['date_created'], 'p_id': '1', 's_id': 7}]
(Background on this error at: https://sqlalche.me/e/20/f405)
2023-04-21 15:38:57,904 - _internal.py._log() on line 224 - INFO - 127.0.0.1 - - [21/Apr/2023 15:38:57] "[31m[1mPOST /api/jobs/create?job_name=job4&frequency=1440&profile_id=1&link=http://example.com/link2 HTTP/1.1[0m" 400 -
2023-04-21 15:40:46,055 - _internal.py._log() on line 224 - INFO -  * Detected change in '/Users/tobychow/Documents/GitHub/Website-Diff-Bot/Services/LoggerContext.py', reloading
2023-04-21 15:40:46,152 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/werkzeug/_internal.py._log() on line 224 - INFO -  * Restarting with stat
2023-04-21 15:40:49,195 - _log() on line 224 in _internal.py- WARNING -  * Debugger is active!
2023-04-21 15:40:49,202 - _log() on line 224 in _internal.py- INFO -  * Debugger PIN: 504-761-569
2023-04-21 15:40:51,231 - scrape_link() on line 14 in WebsiteScraper.py- INFO - Starting Scraping http://example.com/link2. . .
2023-04-21 15:40:51,232 - from_int() on line 351 in retry.py- DEBUG - Converted retries value: 0 -> Retry(total=0, connect=None, read=None, redirect=0, status=None)
2023-04-21 15:40:51,232 - _new_conn() on line 228 in connectionpool.py- DEBUG - Starting new HTTP connection (1): example.com:80
2023-04-21 15:40:51,400 - _make_request() on line 456 in connectionpool.py- DEBUG - http://example.com:80 "GET /link2 HTTP/1.1" 404 1256
2023-04-21 15:40:51,402 - scrape_link() on line 18 in WebsiteScraper.py- INFO - Scraping Success!
2023-04-21 15:40:52,395 - create_job() on line 109 in APIRouting.py- ERROR - (psycopg2.errors.DatatypeMismatch) column "date_created" is of type timestamp with time zone but expression is of type text[]
LINE 1: ...mestamp, '2023-04-22T15:40:51.403052'::timestamp, ARRAY['dat...
                                                             ^
HINT:  You will need to rewrite or cast the expression.

[SQL: INSERT INTO "JobsTable" (job_name, frequency, last_updated, next_update, date_created, p_id, s_id) VALUES (%(job_name)s, %(frequency)s, %(last_updated)s, %(next_update)s, %(date_created)s, %(p_id)s, %(s_id)s) RETURNING "JobsTable".j_id]
[parameters: {'job_name': 'job4', 'frequency': '1440', 'last_updated': datetime.datetime(2023, 4, 21, 15, 40, 51, 403052), 'next_update': datetime.datetime(2023, 4, 22, 15, 40, 51, 403052), 'date_created': ['date_created'], 'p_id': '1', 's_id': 8}]
(Background on this error at: https://sqlalche.me/e/20/f405)
2023-04-21 15:40:52,397 - _log() on line 224 in _internal.py- INFO - 127.0.0.1 - - [21/Apr/2023 15:40:52] "[31m[1mPOST /api/jobs/create?job_name=job4&frequency=1440&profile_id=1&link=http://example.com/link2 HTTP/1.1[0m" 400 -
2023-04-21 15:41:18,412 - _log() on line 224 in _internal.py- INFO -  * Detected change in '/Users/tobychow/Documents/GitHub/Website-Diff-Bot/Services/LoggerContext.py', reloading
2023-04-21 15:41:18,486 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/werkzeug/_internal.py._log() on line 224 - INFO -  * Restarting with stat
2023-04-21 15:41:21,342 - line 224 in _log() in _internal.py - WARNING -  * Debugger is active!
2023-04-21 15:41:21,349 - line 224 in _log() in _internal.py - INFO -  * Debugger PIN: 504-761-569
2023-04-21 15:41:23,080 - line 14 in scrape_link() in WebsiteScraper.py - INFO - Starting Scraping http://example.com/link2. . .
2023-04-21 15:41:23,081 - line 351 in from_int() in retry.py - DEBUG - Converted retries value: 0 -> Retry(total=0, connect=None, read=None, redirect=0, status=None)
2023-04-21 15:41:23,081 - line 228 in _new_conn() in connectionpool.py - DEBUG - Starting new HTTP connection (1): example.com:80
2023-04-21 15:41:23,256 - line 456 in _make_request() in connectionpool.py - DEBUG - http://example.com:80 "GET /link2 HTTP/1.1" 404 1256
2023-04-21 15:41:23,258 - line 18 in scrape_link() in WebsiteScraper.py - INFO - Scraping Success!
2023-04-21 15:41:24,280 - line 109 in create_job() in APIRouting.py - ERROR - (psycopg2.errors.DatatypeMismatch) column "date_created" is of type timestamp with time zone but expression is of type text[]
LINE 1: ...mestamp, '2023-04-22T15:41:23.258549'::timestamp, ARRAY['dat...
                                                             ^
HINT:  You will need to rewrite or cast the expression.

[SQL: INSERT INTO "JobsTable" (job_name, frequency, last_updated, next_update, date_created, p_id, s_id) VALUES (%(job_name)s, %(frequency)s, %(last_updated)s, %(next_update)s, %(date_created)s, %(p_id)s, %(s_id)s) RETURNING "JobsTable".j_id]
[parameters: {'job_name': 'job4', 'frequency': '1440', 'last_updated': datetime.datetime(2023, 4, 21, 15, 41, 23, 258549), 'next_update': datetime.datetime(2023, 4, 22, 15, 41, 23, 258549), 'date_created': ['date_created'], 'p_id': '1', 's_id': 9}]
(Background on this error at: https://sqlalche.me/e/20/f405)
2023-04-21 15:41:24,282 - line 224 in _log() in _internal.py - INFO - 127.0.0.1 - - [21/Apr/2023 15:41:24] "[31m[1mPOST /api/jobs/create?job_name=job4&frequency=1440&profile_id=1&link=http://example.com/link2 HTTP/1.1[0m" 400 -
2023-04-21 15:44:19,322 - line 224 in _log() in _internal.py - INFO -  * Detected change in '/Users/tobychow/Documents/GitHub/Website-Diff-Bot/Models/DBGateway.py', reloading
2023-04-21 15:44:19,385 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/werkzeug/_internal.py._log() on line 224 - INFO -  * Restarting with stat
2023-04-21 15:44:22,651 - line 224 in _log() in _internal.py - WARNING -  * Debugger is active!
2023-04-21 15:44:22,659 - line 224 in _log() in _internal.py - INFO -  * Debugger PIN: 504-761-569
2023-04-21 15:47:03,066 - line 224 in _log() in _internal.py - INFO -  * Detected change in '/Users/tobychow/Documents/GitHub/Website-Diff-Bot/Models/DBGateway.py', reloading
2023-04-21 15:47:03,140 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/werkzeug/_internal.py._log() on line 224 - INFO -  * Restarting with stat
2023-04-21 15:47:06,784 - line 224 in _log() in _internal.py - WARNING -  * Debugger is active!
2023-04-21 15:47:06,794 - line 224 in _log() in _internal.py - INFO -  * Debugger PIN: 504-761-569
2023-04-21 15:47:16,062 - line 224 in _log() in _internal.py - INFO -  * Detected change in '/Users/tobychow/Documents/GitHub/Website-Diff-Bot/Models/DBGateway.py', reloading
2023-04-21 15:47:16,183 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/werkzeug/_internal.py._log() on line 224 - INFO -  * Restarting with stat
2023-04-21 15:47:19,333 - line 224 in _log() in _internal.py - WARNING -  * Debugger is active!
2023-04-21 15:47:19,342 - line 224 in _log() in _internal.py - INFO -  * Debugger PIN: 504-761-569
2023-04-21 15:47:48,562 - line 224 in _log() in _internal.py - INFO -  * Detected change in '/Users/tobychow/Documents/GitHub/Website-Diff-Bot/Models/DBGateway.py', reloading
2023-04-21 15:47:48,662 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/werkzeug/_internal.py._log() on line 224 - INFO -  * Restarting with stat
2023-04-21 15:47:51,914 - line 224 in _log() in _internal.py - WARNING -  * Debugger is active!
2023-04-21 15:47:51,921 - line 224 in _log() in _internal.py - INFO -  * Debugger PIN: 504-761-569
2023-04-21 15:48:24,384 - line 224 in _log() in _internal.py - INFO -  * Detected change in '/Users/tobychow/Documents/GitHub/Website-Diff-Bot/Models/DBGateway.py', reloading
2023-04-21 15:48:24,457 - /Users/tobychow/Documents/GitHub/Website-Diff-Bot/venv/lib/python3.8/site-packages/werkzeug/_internal.py._log() on line 224 - INFO -  * Restarting with stat
2023-04-21 15:50:35,577 - line 224 in _log() in _internal.py - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2023-04-21 15:50:35,577 - line 224 in _log() in _internal.py - INFO - [33mPress CTRL+C to quit[0m
2023-04-21 15:50:35,578 - line 224 in _log() in _internal.py - INFO -  * Restarting with stat
2023-04-21 15:50:38,459 - line 224 in _log() in _internal.py - WARNING -  * Debugger is active!
2023-04-21 15:50:38,466 - line 224 in _log() in _internal.py - INFO -  * Debugger PIN: 504-761-569
2023-04-21 15:53:49,402 - line 224 in _log() in _internal.py - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2023-04-21 15:53:49,402 - line 224 in _log() in _internal.py - INFO - [33mPress CTRL+C to quit[0m
2023-04-21 15:53:49,405 - line 224 in _log() in _internal.py - INFO -  * Restarting with stat
2023-04-21 15:53:53,043 - line 224 in _log() in _internal.py - WARNING -  * Debugger is active!
2023-04-21 15:53:53,053 - line 224 in _log() in _internal.py - INFO -  * Debugger PIN: 504-761-569
2023-04-21 15:53:54,214 - line 14 in scrape_link() in WebsiteScraper.py - INFO - Starting Scraping http://example.com/link2. . .
2023-04-21 15:53:54,215 - line 351 in from_int() in retry.py - DEBUG - Converted retries value: 0 -> Retry(total=0, connect=None, read=None, redirect=0, status=None)
2023-04-21 15:53:54,216 - line 228 in _new_conn() in connectionpool.py - DEBUG - Starting new HTTP connection (1): example.com:80
2023-04-21 15:53:54,409 - line 456 in _make_request() in connectionpool.py - DEBUG - http://example.com:80 "GET /link2 HTTP/1.1" 404 1256
2023-04-21 15:53:54,416 - line 18 in scrape_link() in WebsiteScraper.py - INFO - Scraping Success!
2023-04-21 15:55:13,945 - line 224 in _log() in _internal.py - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2023-04-21 15:55:13,945 - line 224 in _log() in _internal.py - INFO - [33mPress CTRL+C to quit[0m
2023-04-21 15:55:13,947 - line 224 in _log() in _internal.py - INFO -  * Restarting with stat
2023-04-21 15:55:16,815 - line 224 in _log() in _internal.py - WARNING -  * Debugger is active!
2023-04-21 15:55:16,822 - line 224 in _log() in _internal.py - INFO -  * Debugger PIN: 504-761-569
2023-04-21 15:55:19,630 - line 14 in scrape_link() in WebsiteScraper.py - INFO - Starting Scraping http://example.com/link2. . .
2023-04-21 15:55:19,630 - line 351 in from_int() in retry.py - DEBUG - Converted retries value: 0 -> Retry(total=0, connect=None, read=None, redirect=0, status=None)
2023-04-21 15:55:19,631 - line 228 in _new_conn() in connectionpool.py - DEBUG - Starting new HTTP connection (1): example.com:80
2023-04-21 15:55:19,804 - line 456 in _make_request() in connectionpool.py - DEBUG - http://example.com:80 "GET /link2 HTTP/1.1" 404 1256
2023-04-21 15:55:19,805 - line 18 in scrape_link() in WebsiteScraper.py - INFO - Scraping Success!
2023-04-21 15:55:20,810 - line 109 in create_job() in APIRouting.py - ERROR - (psycopg2.errors.DatatypeMismatch) column "date_created" is of type timestamp with time zone but expression is of type text[]
LINE 1: ...mestamp, '2023-04-22T15:55:19.805870'::timestamp, ARRAY['dat...
                                                             ^
HINT:  You will need to rewrite or cast the expression.

[SQL: INSERT INTO "JobsTable" (job_name, frequency, last_updated, next_update, date_created, p_id, s_id) VALUES (%(job_name)s, %(frequency)s, %(last_updated)s, %(next_update)s, %(date_created)s, %(p_id)s, %(s_id)s) RETURNING "JobsTable".j_id]
[parameters: {'job_name': 'job4', 'frequency': '1440', 'last_updated': datetime.datetime(2023, 4, 21, 15, 55, 19, 805870), 'next_update': datetime.datetime(2023, 4, 22, 15, 55, 19, 805870), 'date_created': ['date_created'], 'p_id': '1', 's_id': 11}]
(Background on this error at: https://sqlalche.me/e/20/f405)
2023-04-21 15:55:20,812 - line 224 in _log() in _internal.py - INFO - 127.0.0.1 - - [21/Apr/2023 15:55:20] "[31m[1mPOST /api/jobs/create?job_name=job4&frequency=1440&profile_id=1&link=http://example.com/link2 HTTP/1.1[0m" 400 -
2023-04-21 15:55:47,304 - line 224 in _log() in _internal.py - INFO -  * Detected change in '/Users/tobychow/Documents/GitHub/Website-Diff-Bot/Models/DBGateway.py', reloading
2023-04-21 15:55:47,405 - line 224 in _log() in _internal.py - INFO -  * Restarting with stat
2023-04-21 15:55:50,602 - line 224 in _log() in _internal.py - WARNING -  * Debugger is active!
2023-04-21 15:55:50,609 - line 224 in _log() in _internal.py - INFO -  * Debugger PIN: 504-761-569
2023-04-21 15:55:51,275 - line 14 in scrape_link() in WebsiteScraper.py - INFO - Starting Scraping http://example.com/link2. . .
2023-04-21 15:55:51,275 - line 351 in from_int() in retry.py - DEBUG - Converted retries value: 0 -> Retry(total=0, connect=None, read=None, redirect=0, status=None)
2023-04-21 15:55:51,275 - line 228 in _new_conn() in connectionpool.py - DEBUG - Starting new HTTP connection (1): example.com:80
2023-04-21 15:55:51,438 - line 456 in _make_request() in connectionpool.py - DEBUG - http://example.com:80 "GET /link2 HTTP/1.1" 404 1256
2023-04-21 15:55:51,440 - line 18 in scrape_link() in WebsiteScraper.py - INFO - Scraping Success!
2023-04-21 15:55:52,554 - line 109 in create_job() in APIRouting.py - ERROR - (psycopg2.errors.DatatypeMismatch) column "date_created" is of type timestamp with time zone but expression is of type text[]
LINE 1: ...mestamp, '2023-04-22T15:55:51.440503'::timestamp, ARRAY['dat...
                                                             ^
HINT:  You will need to rewrite or cast the expression.

[SQL: INSERT INTO "JobsTable" (job_name, frequency, last_updated, next_update, date_created, p_id, s_id) VALUES (%(job_name)s, %(frequency)s, %(last_updated)s, %(next_update)s, %(date_created)s, %(p_id)s, %(s_id)s) RETURNING "JobsTable".j_id]
[parameters: {'job_name': 'job4', 'frequency': '1440', 'last_updated': datetime.datetime(2023, 4, 21, 15, 55, 51, 440503), 'next_update': datetime.datetime(2023, 4, 22, 15, 55, 51, 440503), 'date_created': ['date_created'], 'p_id': '1', 's_id': 12}]
(Background on this error at: https://sqlalche.me/e/20/f405)
2023-04-21 15:55:52,556 - line 224 in _log() in _internal.py - INFO - 127.0.0.1 - - [21/Apr/2023 15:55:52] "[31m[1mPOST /api/jobs/create?job_name=job4&frequency=1440&profile_id=1&link=http://example.com/link2 HTTP/1.1[0m" 400 -
2023-04-21 15:56:46,362 - line 224 in _log() in _internal.py - INFO -  * Detected change in '/Users/tobychow/Documents/GitHub/Website-Diff-Bot/Models/DBGateway.py', reloading
2023-04-21 15:56:46,454 - line 224 in _log() in _internal.py - INFO -  * Restarting with stat
2023-04-21 15:56:49,418 - line 224 in _log() in _internal.py - WARNING -  * Debugger is active!
2023-04-21 15:56:49,426 - line 224 in _log() in _internal.py - INFO -  * Debugger PIN: 504-761-569
2023-04-21 15:56:54,049 - line 224 in _log() in _internal.py - INFO -  * Detected change in '/Users/tobychow/Documents/GitHub/Website-Diff-Bot/Models/DBGateway.py', reloading
2023-04-21 15:56:54,135 - line 224 in _log() in _internal.py - INFO -  * Restarting with stat
2023-04-21 15:56:57,047 - line 224 in _log() in _internal.py - WARNING -  * Debugger is active!
2023-04-21 15:56:57,054 - line 224 in _log() in _internal.py - INFO -  * Debugger PIN: 504-761-569
2023-04-21 15:56:57,723 - line 14 in scrape_link() in WebsiteScraper.py - INFO - Starting Scraping http://example.com/link2. . .
2023-04-21 15:56:57,724 - line 351 in from_int() in retry.py - DEBUG - Converted retries value: 0 -> Retry(total=0, connect=None, read=None, redirect=0, status=None)
2023-04-21 15:56:57,724 - line 228 in _new_conn() in connectionpool.py - DEBUG - Starting new HTTP connection (1): example.com:80
2023-04-21 15:56:57,894 - line 456 in _make_request() in connectionpool.py - DEBUG - http://example.com:80 "GET /link2 HTTP/1.1" 404 1256
2023-04-21 15:56:57,896 - line 18 in scrape_link() in WebsiteScraper.py - INFO - Scraping Success!
2023-04-21 15:56:59,278 - line 224 in _log() in _internal.py - INFO - 127.0.0.1 - - [21/Apr/2023 15:56:59] "POST /api/jobs/create?job_name=job4&frequency=1440&profile_id=1&link=http://example.com/link2 HTTP/1.1" 200 -
2023-04-21 15:57:06,578 - line 109 in create_job() in APIRouting.py - ERROR - Job with job name job4 already exists
2023-04-21 15:57:06,677 - line 224 in _log() in _internal.py - INFO - 127.0.0.1 - - [21/Apr/2023 15:57:06] "[31m[1mPOST /api/jobs/create?job_name=job4&frequency=1440&profile_id=1&link=http://example.com/link2 HTTP/1.1[0m" 400 -
2023-04-21 15:57:16,318 - line 14 in scrape_link() in WebsiteScraper.py - INFO - Starting Scraping https://www.sacanime.com/vendors-and-artists/artist-alley/artist-alley-registration/. . .
2023-04-21 15:57:16,319 - line 351 in from_int() in retry.py - DEBUG - Converted retries value: 0 -> Retry(total=0, connect=None, read=None, redirect=0, status=None)
2023-04-21 15:57:16,319 - line 1003 in _new_conn() in connectionpool.py - DEBUG - Starting new HTTPS connection (1): www.sacanime.com:443
2023-04-21 15:57:17,020 - line 32 in __get_raw_html_from_link() in WebsiteScraper.py - WARNING - Failed with: HTTPSConnectionPool(host='www.sacanime.com', port=443): Max retries exceeded with url: /vendors-and-artists/artist-alley/artist-alley-registration/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)')))
2023-04-21 15:57:17,020 - line 33 in __get_raw_html_from_link() in WebsiteScraper.py - WARNING - Will try again with non-secure connection ...
2023-04-21 15:57:17,021 - line 351 in from_int() in retry.py - DEBUG - Converted retries value: 0 -> Retry(total=0, connect=None, read=None, redirect=0, status=None)
2023-04-21 15:57:17,022 - line 1003 in _new_conn() in connectionpool.py - DEBUG - Starting new HTTPS connection (1): www.sacanime.com:443
2023-04-21 15:57:17,374 - line 456 in _make_request() in connectionpool.py - DEBUG - https://www.sacanime.com:443 "GET /vendors-and-artists/artist-alley/artist-alley-registration/ HTTP/1.1" 200 212
2023-04-21 15:57:17,376 - line 18 in scrape_link() in WebsiteScraper.py - INFO - Scraping Success!
2023-04-21 15:57:19,078 - line 14 in scrape_link() in WebsiteScraper.py - INFO - Starting Scraping http://example.com/link2. . .
2023-04-21 15:57:19,078 - line 351 in from_int() in retry.py - DEBUG - Converted retries value: 0 -> Retry(total=0, connect=None, read=None, redirect=0, status=None)
2023-04-21 15:57:19,078 - line 228 in _new_conn() in connectionpool.py - DEBUG - Starting new HTTP connection (1): example.com:80
2023-04-21 15:57:19,233 - line 456 in _make_request() in connectionpool.py - DEBUG - http://example.com:80 "GET /link2 HTTP/1.1" 404 1256
2023-04-21 15:57:19,235 - line 18 in scrape_link() in WebsiteScraper.py - INFO - Scraping Success!
2023-04-21 15:57:20,979 - line 224 in _log() in _internal.py - INFO - 127.0.0.1 - - [21/Apr/2023 15:57:20] "POST /api/jobs/all/refresh HTTP/1.1" 200 -
2023-04-21 15:58:12,330 - line 224 in _log() in _internal.py - INFO -  * Detected change in '/Users/tobychow/Documents/GitHub/Website-Diff-Bot/Services/APIUtils.py', reloading
2023-04-21 15:58:12,424 - line 224 in _log() in _internal.py - INFO -  * Restarting with stat
2023-04-21 15:58:15,756 - line 224 in _log() in _internal.py - WARNING -  * Debugger is active!
2023-04-21 15:58:15,765 - line 224 in _log() in _internal.py - INFO -  * Debugger PIN: 504-761-569
2023-04-21 16:00:22,129 - line 224 in _log() in _internal.py - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2023-04-21 16:00:22,129 - line 224 in _log() in _internal.py - INFO - [33mPress CTRL+C to quit[0m
2023-04-21 16:00:22,130 - line 224 in _log() in _internal.py - INFO -  * Restarting with stat
2023-04-21 16:00:25,180 - line 224 in _log() in _internal.py - WARNING -  * Debugger is active!
2023-04-21 16:00:25,186 - line 224 in _log() in _internal.py - INFO -  * Debugger PIN: 504-761-569
2023-04-21 16:00:27,568 - line 224 in _log() in _internal.py - INFO - 127.0.0.1 - - [21/Apr/2023 16:00:27] "POST /api/jobs/all/refresh HTTP/1.1" 200 -
2023-04-21 16:01:05,668 - line 14 in scrape_link() in WebsiteScraper.py - INFO - Starting Scraping https://www.sacanime.com/vendors-and-artists/artist-alley/artist-alley-registration/. . .
2023-04-21 16:01:05,669 - line 351 in from_int() in retry.py - DEBUG - Converted retries value: 0 -> Retry(total=0, connect=None, read=None, redirect=0, status=None)
2023-04-21 16:01:05,669 - line 1003 in _new_conn() in connectionpool.py - DEBUG - Starting new HTTPS connection (1): www.sacanime.com:443
2023-04-21 16:01:06,382 - line 32 in __get_raw_html_from_link() in WebsiteScraper.py - WARNING - Failed with: HTTPSConnectionPool(host='www.sacanime.com', port=443): Max retries exceeded with url: /vendors-and-artists/artist-alley/artist-alley-registration/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)')))
2023-04-21 16:01:06,382 - line 33 in __get_raw_html_from_link() in WebsiteScraper.py - WARNING - Will try again with non-secure connection ...
2023-04-21 16:01:06,383 - line 351 in from_int() in retry.py - DEBUG - Converted retries value: 0 -> Retry(total=0, connect=None, read=None, redirect=0, status=None)
2023-04-21 16:01:06,383 - line 1003 in _new_conn() in connectionpool.py - DEBUG - Starting new HTTPS connection (1): www.sacanime.com:443
2023-04-21 16:01:06,757 - line 456 in _make_request() in connectionpool.py - DEBUG - https://www.sacanime.com:443 "GET /vendors-and-artists/artist-alley/artist-alley-registration/ HTTP/1.1" 200 828
2023-04-21 16:01:06,759 - line 18 in scrape_link() in WebsiteScraper.py - INFO - Scraping Success!
2023-04-21 16:01:07,968 - line 41 in test_send_email_success() in EmailManager.py - INFO - Successfully sent email !!!
2023-04-21 16:01:09,293 - line 224 in _log() in _internal.py - INFO - 127.0.0.1 - - [21/Apr/2023 16:01:09] "POST /api/jobs/all/refresh HTTP/1.1" 200 -
2023-04-21 16:02:00,335 - line 224 in _log() in _internal.py - INFO -  * Detected change in '/Users/tobychow/Documents/GitHub/Website-Diff-Bot/Services/WebsiteScraper.py', reloading
2023-04-21 16:02:00,490 - line 224 in _log() in _internal.py - INFO -  * Restarting with stat
2023-04-21 16:02:03,665 - line 224 in _log() in _internal.py - WARNING -  * Debugger is active!
2023-04-21 16:02:03,674 - line 224 in _log() in _internal.py - INFO -  * Debugger PIN: 504-761-569
2023-04-21 16:02:11,827 - line 224 in _log() in _internal.py - INFO -  * Detected change in '/Users/tobychow/Documents/GitHub/Website-Diff-Bot/Services/WebsiteScraper.py', reloading
2023-04-21 16:02:11,928 - line 224 in _log() in _internal.py - INFO -  * Restarting with stat
2023-04-21 16:02:15,176 - line 224 in _log() in _internal.py - WARNING -  * Debugger is active!
2023-04-21 16:02:15,183 - line 224 in _log() in _internal.py - INFO -  * Debugger PIN: 504-761-569
